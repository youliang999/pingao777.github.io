---
title: 统计中的p值
date: 2016-03-20 11:36:27
categories: 技术人生
tags: 统计
---

在我看来，假设检验从本质上是一种反证法。当你想证明一样事物是对的，有时候不太好证明，因为一件你以为对的东西可能只是因为你还没发现它错的一面，相反你想证明一件事物是错的就容易多了。在假设检验中，证明备择假设H1存在困难，我们就去证明它的反面原假设H0。

<!-- more -->

p值一直是一个令人迷惑的地方，p值实际上是当H0假设为真，一些极端情况出现的概率。即
$$
p值 = \{极端情况概率|H0\}
$$

那么极端情况是什么呢？在H0的前提下，假设样本均值符合正态分布，我们都知道偏离均值3个均方差的概率几乎为0，但是这种情况还是出现了，我们就有理由判断前提条件错了，即H0是错的，由此我们拒绝H0。

上面提到在正态分布的情况下，偏离均值3个均方差的概率几乎为0，但毕竟不是0，事实上约为0.27%。虽然概率很小，但是还是有一定的可能性会拒绝本是正确的H0，这个犯错概率称为第一类错误，也称为显著性水平$\alpha$。

那么，这个显著性水平$\alpha$和p值有什么关系呢？在我看来就是拒绝一个真H0所允许的最大错误概率，也就是这种极端情况出现的最高概率，当p小于等于$\alpha$时我们拒绝H0，否则不能拒绝H0。

在假设检验中，通常的流程为：
1. 提出原假设和备择假设。
2. 指定显著性水平$\alpha$，通常取0.01或0.05。
3. 搜集样本数据计算检验统计量的值。
4. 利用检验统计量的值计算p值。
5. 如果p值<=$\alpha$，则拒绝H0，否则不能拒绝H0。
